import pandas as pd
import networkx as nx
import numpy as np
from faker import Faker # for fake names


# generating 30 fake people
fake = Faker()
num_people = 30

# generating attributes
nodes = pd.DataFrame({
    'id': range(num_people),
    'name': [fake.name() for _ in range(num_people)],
    'age': np.random.randint(18, 65, num_people),
    'role': np.random.choice(['Strudent', 'Teacher', 'Admin'], num_people)
})


# generating a graph
G = nx.Graph()

# add random nodes to the graph
G.add_nodes_from(nodes['id'])

# add random edges (relationships)
for i in range(num_people):
    for j in range(i + 1, num_people):
        if np.random.random() < 0.1: # 10% chance of connection
            weight = np.random.randint(1, 5) # random interaction strenght
            G.add_edge(i, j, weight=weight, type=np.random.choice(['friend', 'colleague']))


degree_centrality = nx.degree_centrality(G)
print("Most connected people:",
      sorted(degree_centrality.items(),
     key=lambda x: x[1],
     reverse=True)[:3])


# Calculate degree centrality (number of connections per person)
degree_centrality = nx.degree_centrality(G)  # Returns normalized values (0 to 1)
degrees = dict(G.degree())                  # Get raw connection counts

# Map node IDs to names
node_names = {node_id: nodes.loc[nodes['id'] == node_id, 'name'].values[0] for node_id in G.nodes()}

# Sort people by number of connections (descending order)
sorted_degrees = sorted(degrees.items(), key=lambda x: x[1], reverse=True)

# Print top N people with their names and connection counts
num_top = 5  # Change this to show more/fewer people
print(f"Top {num_top} Most Connected People:")
for node_id, degree in sorted_degrees[:num_top]:
    print(f"{node_names[node_id]}: {degree} connections")



